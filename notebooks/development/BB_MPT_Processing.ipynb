{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2398d59",
   "metadata": {},
   "source": [
    "## Importing Packages ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65750f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import tempfile\n",
    "import random\n",
    "from itertools import compress\n",
    "import os.path as op\n",
    "import numpy as np\n",
    "import skimage.io as sio\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import math\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir, getcwd, chdir\n",
    "from os.path import isfile, join\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "import diff_classifier\n",
    "import diff_classifier.utils as ut\n",
    "import diff_classifier.msd as msd\n",
    "import diff_classifier.features as ft\n",
    "import diff_classifier.heatmaps as hm\n",
    "import diff_classifier.aws as aws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9556aa24",
   "metadata": {},
   "source": [
    "## Defining filename and importing video - will eventually convert to a for loop to loop through list of videos ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a79bd27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiffname = 'P10F_NT_4DIV_40nm_slice_1_cortex_vid_2.tiff'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06579317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(651, 2044, 2048)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('/Users/claudialozano/Dropbox/PycharmProjects/AD_nanoparticle/diff_classifier/notebooks/development/MPT_Data/{}/'.format(tiffname.replace('.tiff', '')))\n",
    "test = sio.imread(tiffname)\n",
    "oshape = test.shape\n",
    "oshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e37dfc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/claudialozano/Dropbox/PycharmProjects/AD_nanoparticle/diff_classifier/notebooks/development/MPT_Data/P10F_NT_4DIV_40nm_slice_1_cortex_vid_2'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4623a360",
   "metadata": {},
   "source": [
    "## Splitting original 2048x2044 video into smaller videos - takes the video imported just above and splits it into 64 256x256 smaller videos - could potentially adjust this to split into 25 or 36 vids, but for now keeping at 64 (easier to track the small vids) ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0295ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = np.zeros((oshape[0], 2048, 2048), dtype=test.dtype)\n",
    "test2[0:oshape[0], 0:oshape[1], :] = test\n",
    "\n",
    "new_image = np.zeros((oshape[0], 512, 512), dtype=test.dtype)\n",
    "names = []\n",
    "\n",
    "for row in range(4):\n",
    "    for col in range(4):\n",
    "        new_image = test2[:, row*512:(row+1)*512, col*512:(col+1)*512]\n",
    "        current = tiffname.split('.tif')[0] + '_%s_%s.tif' % (row, col)\n",
    "        sio.imsave(current, new_image)\n",
    "        names.append(current)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542bebd0",
   "metadata": {},
   "source": [
    "## For now, tracking is done manually using the plugin TrackMate in ImageJ. The cells located below this can be used to rename the trajectory .csv files to the proper 'Traj_... .csv' format ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033b6958",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88943cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Traj_1_2_P10F_NT_4DIV_40nm_slice_1_cortex_vid_2.csv', 'Traj_3_1_P10F_NT_4DIV_40nm_slice_1_cortex_vid_2.csv', 'Traj_3_3_P10F_NT_4DIV_40nm_slice_1_cortex_vid_2.csv', 'Traj_1_0_P10F_NT_4DIV_40nm_slice_1_cortex_vid_2.csv', 'Traj_1_3_P10F_NT_4DIV_40nm_slice_1_cortex_vid_2.csv', 'Traj_3_0_P10F_NT_4DIV_40nm_slice_1_cortex_vid_2.csv', 'Traj_3_2_P10F_NT_4DIV_40nm_slice_1_cortex_vid_2.csv', 'Traj_1_1_P10F_NT_4DIV_40nm_slice_1_cortex_vid_2.csv', 'Traj_2_2_P10F_NT_4DIV_40nm_slice_1_cortex_vid_2.csv', 'Traj_0_1_P10F_NT_4DIV_40nm_slice_1_cortex_vid_2.csv', 'Traj_0_3_P10F_NT_4DIV_40nm_slice_1_cortex_vid_2.csv', 'Traj_2_0_P10F_NT_4DIV_40nm_slice_1_cortex_vid_2.csv', 'Traj_2_3_P10F_NT_4DIV_40nm_slice_1_cortex_vid_2.csv', 'Traj_0_0_P10F_NT_4DIV_40nm_slice_1_cortex_vid_2.csv', 'Traj_0_2_P10F_NT_4DIV_40nm_slice_1_cortex_vid_2.csv', 'Traj_2_1_P10F_NT_4DIV_40nm_slice_1_cortex_vid_2.csv']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "files = glob.glob('Traj*.csv')\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007c4b0b",
   "metadata": {},
   "source": [
    "## Defining list of all small videos to be quantified (calculating msds and features) ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cccf57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = tiffname.replace('.tiff', '')\n",
    "rows = 4\n",
    "cols = 4\n",
    "ires = (512, 512)\n",
    "frames = 651\n",
    "names = []\n",
    "for i in range(0,rows):\n",
    "    for j in range(0,cols):\n",
    "        names.append('{}_{}_{}.tif'.format(filename, i, j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "899db831",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'merged' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmerged\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'merged' is not defined"
     ]
    }
   ],
   "source": [
    "merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce0de9d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['P10F_NT_4DIV_40nm_slice_1_cortex_vid_2_0_0.tif',\n",
       " 'P10F_NT_4DIV_40nm_slice_1_cortex_vid_2_0_1.tif',\n",
       " 'P10F_NT_4DIV_40nm_slice_1_cortex_vid_2_0_2.tif',\n",
       " 'P10F_NT_4DIV_40nm_slice_1_cortex_vid_2_0_3.tif',\n",
       " 'P10F_NT_4DIV_40nm_slice_1_cortex_vid_2_1_0.tif',\n",
       " 'P10F_NT_4DIV_40nm_slice_1_cortex_vid_2_1_1.tif',\n",
       " 'P10F_NT_4DIV_40nm_slice_1_cortex_vid_2_1_2.tif',\n",
       " 'P10F_NT_4DIV_40nm_slice_1_cortex_vid_2_1_3.tif',\n",
       " 'P10F_NT_4DIV_40nm_slice_1_cortex_vid_2_2_0.tif',\n",
       " 'P10F_NT_4DIV_40nm_slice_1_cortex_vid_2_2_1.tif',\n",
       " 'P10F_NT_4DIV_40nm_slice_1_cortex_vid_2_2_2.tif',\n",
       " 'P10F_NT_4DIV_40nm_slice_1_cortex_vid_2_2_3.tif',\n",
       " 'P10F_NT_4DIV_40nm_slice_1_cortex_vid_2_3_0.tif',\n",
       " 'P10F_NT_4DIV_40nm_slice_1_cortex_vid_2_3_1.tif',\n",
       " 'P10F_NT_4DIV_40nm_slice_1_cortex_vid_2_3_2.tif',\n",
       " 'P10F_NT_4DIV_40nm_slice_1_cortex_vid_2_3_3.tif']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6719ded",
   "metadata": {},
   "source": [
    "## Calculating MSDs and features for the videos that have been tracked. This uses the Traj .csv files and generates an msd and features .csv file for the videos being quantified. It uses the multiple small vid Traj .csv files to generate a single msd and features .csv file. Essentially, this runs the kn.assemble_msds() function ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "326af493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traj_0_0_P10F_NT_4DIV_40nm_slice_1_cortex_vid_2.csv\n",
      "Finished with row 0 col 0\n",
      "OUT\n"
     ]
    }
   ],
   "source": [
    "ft_file = 'features_{}.csv'.format(filename)\n",
    "msd_file = 'msd_{}.csv'.format(filename)\n",
    "toadd_file = 'toadd_{}.csv'.format(filename)\n",
    "\n",
    "counter = 0\n",
    "for name in names:\n",
    "    try:\n",
    "    \n",
    "        row = int(name.split(filename)[1].split('.')[0].split('_')[1])\n",
    "        col = int(name.split(filename)[1].split('.')[0].split('_')[2])\n",
    "    \n",
    "        traj_file = \"Traj_{}_{}_{}.csv\".format(row, col, filename)\n",
    "        local_name = traj_file\n",
    "        print(local_name)\n",
    "    \n",
    "        if counter == 0:\n",
    "            to_add = pd.read_csv(local_name)\n",
    "            to_add = to_add.iloc[3:]\n",
    "            del to_add['LABEL']\n",
    "            del to_add['POSITION_Z']\n",
    "            del to_add['POSITION_T']\n",
    "            del to_add['RADIUS']\n",
    "            del to_add['VISIBILITY']\n",
    "            del to_add['MANUAL_SPOT_COLOR']\n",
    "            del to_add['MEDIAN_INTENSITY_CH1']\n",
    "            del to_add['MIN_INTENSITY_CH1']\n",
    "            del to_add['MAX_INTENSITY_CH1']\n",
    "            del to_add['TOTAL_INTENSITY_CH1']\n",
    "            del to_add['STD_INTENSITY_CH1']\n",
    "            #del to_add['ESTIMATED_DIAMETER']\n",
    "            del to_add['CONTRAST_CH1']\n",
    "            to_add = to_add.rename(columns={'ID':'Spot_ID', 'TRACK_ID':'Track_ID','QUALITY':'Quality','FRAME':'Frame', 'POSITION_X':'X','POSITION_Y':'Y', 'MEAN_INTENSITY_CH1':'Mean_Intensity', 'SNR_CH1':'SN_Ratio'})\n",
    "            to_add.sort_values(['Track_ID', 'Frame'], ascending=[1,1])\n",
    "            to_add = to_add.astype('float64')\n",
    "\n",
    "            partids = to_add.Track_ID.unique()\n",
    "            counter = 0\n",
    "            for partid in partids:\n",
    "                to_add.loc[to_add.Track_ID == partid, 'Track_ID'] = counter\n",
    "                counter = counter +1\n",
    "            to_add['X'] = to_add['X'] + ires[0]*col\n",
    "            to_add['Y'] = ires[1]-to_add['Y']+ires[1]*(rows-1-row)\n",
    "            merged = msd.all_msds2(to_add, frames=frames)\n",
    "            to_add.to_csv(toadd_file)\n",
    "            merged.to_csv(msd_file)\n",
    "            print(\"Finished with row 0 col 0\")\n",
    "            break\n",
    "            \n",
    "\n",
    "        else:\n",
    "        \n",
    "            if merged.shape[0] > 0:\n",
    "                print(\"MERGED_SHAPE:\", merged.shape)\n",
    "                to_add = pd.read_csv(local_name)\n",
    "                to_add = to_add.iloc[3:]\n",
    "                del to_add['LABEL']\n",
    "                del to_add['POSITION_Z']\n",
    "                del to_add['POSITION_T']\n",
    "                del to_add['RADIUS']\n",
    "                del to_add['VISIBILITY']\n",
    "                del to_add['MANUAL_SPOT_COLOR']\n",
    "                del to_add['MEDIAN_INTENSITY_CH1']\n",
    "                del to_add['MIN_INTENSITY_CH1']\n",
    "                del to_add['MAX_INTENSITY_CH1']\n",
    "                del to_add['TOTAL_INTENSITY_CH1']\n",
    "                del to_add['STD_INTENSITY_CH1']\n",
    "                #del to_add['ESTIMATED_DIAMETER']\n",
    "                del to_add['CONTRAST_CH1']\n",
    "                to_add = to_add.rename(columns={'ID':'Spot_ID', 'TRACK_ID':'Track_ID','QUALITY':'Quality','FRAME':'Frame', 'POSITION_X':'X','POSITION_Y':'Y', 'MEAN_INTENSITY_CH1':'Mean_Intensity', 'SNR_CH1':'SN_Ratio'})\n",
    "                to_add.sort_values(['Track_ID', 'Frame'], ascending=[1,1])\n",
    "                to_add = to_add.astype('float64')\n",
    "\n",
    "                partids = to_add.Track_ID.unique()\n",
    "                counter = 0\n",
    "                for partid in partids:\n",
    "                    to_add.loc[to_add.Track_ID == partid, 'Track_ID'] = counter\n",
    "                    counter = counter +1\n",
    "                to_add['X'] = to_add['X'] + ires[0]*col\n",
    "                print(ires[0]*col)\n",
    "                to_add['Y'] = ires[1] - to_add['Y'] + ires[1]*(rows-1-row)\n",
    "                to_add['Track_ID'] = to_add['Track_ID'] + max(merged['Track_ID']) +1\n",
    "    \n",
    "            \n",
    "            else:\n",
    "                print(\"YOOOO GOT HERE\")\n",
    "                to_add = pd.read_csv(local_name)\n",
    "                to_add = to_add.iloc[3:]\n",
    "                del to_add['LABEL']\n",
    "                del to_add['POSITION_Z']\n",
    "                del to_add['POSITION_T']\n",
    "                del to_add['RADIUS']\n",
    "                del to_add['VISIBILITY']\n",
    "                del to_add['MANUAL_SPOT_COLOR']\n",
    "                del to_add['MEDIAN_INTENSITY_CH1']\n",
    "                del to_add['MIN_INTENSITY_CH1']\n",
    "                del to_add['MAX_INTENSITY_CH1']\n",
    "                del to_add['TOTAL_INTENSITY_CH1']\n",
    "                del to_add['STD_INTENSITY_CH1']\n",
    "                #del to_add['ESTIMATED_DIAMETER']\n",
    "                del to_add['CONTRAST_CH1']\n",
    "                to_add = to_add.rename(columns={'ID':'Spot_ID', 'TRACK_ID':'Track_ID','QUALITY':'Quality','FRAME':'Frame', 'POSITION_X':'X','POSITION_Y':'Y', 'MEAN_INTENSITY_CH1':'Mean_Intensity', 'SNR_CH1':'SN_Ratio'})\n",
    "                to_add.sort_values(['Track_ID', 'Frame'], ascending=[1,1])\n",
    "                to_add = to_add.astype('float64')\n",
    "\n",
    "                partids = to_add.Track_ID.unique()\n",
    "                counter = 0\n",
    "                for partid in partids:\n",
    "                    to_add.loc[to_add.Track_ID == partid, 'Track_ID'] = counter\n",
    "                    counter = counter +1\n",
    "                to_add['X'] = to_add['X'] + ires[0]*col\n",
    "                print(to_add['X'] + ires[0]*col)\n",
    "                to_add['Y'] = ires[1] - to_add['Y'] + ires[1]*(rows-1-row)\n",
    "                to_add['Track_ID'] = to_add['Track_ID']\n",
    "            \n",
    "            #print(\"THIS IS MERGED SHAPE\")\n",
    "            #print(merged.shape)\n",
    "            merged = merged.append(msd.all_msds2(to_add, frames=frames))\n",
    "            print('Done calculating MSDs for row {} and col {}'.format(row, col))\n",
    "    \n",
    "        counter = counter +1\n",
    "\n",
    "        merged.to_csv(msd_file)\n",
    "        \n",
    "    except pd.errors.EmptyDataError:\n",
    "        print('Found empty file : {}'.format(name))\n",
    "\n",
    "\n",
    "#merged_ft = ft.calculate_features(merged)\n",
    "#merged_ft.to_csv(ft_file)\n",
    "print('OUT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91234ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/claudialozano/Dropbox/PycharmProjects/AD_nanoparticle/diff_classifier/notebooks/development/MPT_Data/{}/'.format(tiffname.replace('.tiff', '')))\n",
    "prefix = filename\n",
    "msds = 'msd_{}.csv'.format(prefix)\n",
    "feat = 'features_{}.csv'.format(prefix)\n",
    "print(feat)\n",
    "print(msds)\n",
    "hm.plot_trajectories(prefix, resolution=512, rows=4, cols=4, upload=False, figsize=(12, 12), bucket = 'mckenna.data')\n",
    "print('Successfully generated trajectory plot for {}'.format(prefix))\n",
    "geomean, geoSEM = hm.plot_individual_msds(prefix, x_range=2, y_range=10, umppx=0.07, fps=33.33, upload=False, bucket='mckenna.data')\n",
    "print('Successfully generated csv files for {}'.format(prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16164be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "org_feat = 'orig_features_{}.csv'.format(prefix)\n",
    "hm.plot_heatmap(org_feat, resolution=512, rows=4, cols=4, upload=False, figsize=(12, 12), bucket = 'mckenna.data')\n",
    "\n",
    "feat = 'features_{}.csv'.format(prefix)\n",
    "hm.plot_heatmap(feat, resolution=512, rows=4, cols=4, upload=False, figsize=(12, 12), bucket = 'mckenna.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86492bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
